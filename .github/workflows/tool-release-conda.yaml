name: tool-release-conda

on:
  workflow_call:
    inputs:
      python_versions:
        description: 'Python versions'
        type: string
        required: false
        default: "3.11,3.12"
      platforms:
        description: 'Platforms'
        type: string
        required: false
        default: "ubuntu-latest,windows-latest,macos-latest"
      variants_input:
        description: 'Override variants compiled in parallel; <variant1_key>=<variant1_value>,<variant2_key>=<variant2_value>'
        type: string
        required: false
      add_build_args:
        description: 'Additional build arguments'
        type: string
        required: false
        default: ""
      use_quetz_server:
        description: 'Use quetz server'
        type: string
        required: false
        default: "false"
      use_anaconda_server:
        description: 'Use anaconda server'
        type: string
        required: false
        default: "false"
      push_conda:
        description: 'Push to conda'
        type: string
        required: false
        default: false
      version_override:
        description: 'Version override'
        type: string
        required: false
        default: ''
      config_toml_data:
        description: "Toml config file for actions base64 encoded"
        type: string
        required: false
        default: ""
    secrets:
      CONDA_API_TOKEN:
        required: false
      QUETZ_API_KEY:
        required: false
      QUETZ_URL:
        required: false

env:
  ARTIFACTS_DIR: /home/runner/work/artifacts
  CROOT_DIR: /home/runner/work/build
  BUILD_ARGS: ""

jobs:
  extract_conda_meta:
    runs-on: ubuntu-latest
    outputs:
      recipe_dir: ${{ steps.extract_conda_meta.outputs.recipe_dir }}
      quetz_channel: ${{ steps.extract_conda_meta.outputs.quetz_channel }}
      publish_runner: ${{ steps.extract_conda_meta.outputs.publish_runner }}
      artifacts_retention_days: ${{ steps.extract_conda_meta.outputs.artifacts_retention_days }}
      dispatch_release_workflow: ${{ steps.extract_conda_meta.outputs.dispatch_release_workflow }}
    steps:
      - name: Extract recipe_dir
        id: extract_conda_meta
        shell: python
        run: |
          import os
          import json
          import base64
          
          def deserialize_str(s):
            return base64.b64decode(s).decode('utf-8')
          
          def set_output(name, value):
              with open(os.environ["GITHUB_OUTPUT"], "a") as fh:
                  print(f"{name}={value}", file=fh)

          toml_data = json.loads(deserialize_str(b"${{ inputs.config_toml_data }}"))
          
          set_output('recipe_dir', toml_data["tool"]["python"]['conda']['recipe_dir'])
          set_output('quetz_channel', toml_data["tool"]["python"]['conda'].get('quetz_channel', None))
          set_output('publish_runner', toml_data["tool"]["python"]['conda'].get('publish_runner', 'ubuntu-latest'))
          set_output('artifacts_retention_days', toml_data["tool"]["python"]['conda'].get('artifacts_retention_days', '2'))
          set_output('dispatch_release_workflow', toml_data["tool"]["python"]['conda'].get('dispatch_release_workflow', 'conda-release-workflow-on-self-hosted'))
          


  create_variant_matrix:
    needs: extract_conda_meta
    name: Create variant matrix
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    outputs:
      final_matrix: ${{ steps.create_matrix.outputs.final_matrix }}
      conda_owner: ${{ steps.create_matrix.outputs.conda_owner }}
      conda_label: ${{ steps.create_matrix.outputs.conda_label }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}

      - uses: mamba-org/setup-micromamba@v1 # https://github.com/mamba-org/setup-micromamba
        with:
          environment-name: build-env
          cache-environment: true
          condarc: |
            channel_priority: strict
            channels:
              - conda-forge
          create-args: >-
            python=3.11
            boa=0.16.0

      - name: create matrix
        id: create_matrix
        run: |
          # Running "shell: python" appears to only use the system python

          python - << EOF
          import os
          import base64
          import itertools
          import json
          import pathlib

          from boa.core.utils import get_config


          def set_output(name, value):
              with open(os.environ["GITHUB_OUTPUT"], "a") as fh:
                  print(f"{name}={value}", file=fh)
          
          
          def deserialize_str(s):
              return base64.b64decode(s).decode('utf-8')
          
          
          def convert_to_byte_str(var_str: str) -> str:
              encoded_bytes = base64.b64encode(var_str.encode("utf-8"))
              var_bytes_str = encoded_bytes.decode("utf-8")
              return var_bytes_str


          def variants_matrix_gen(recipe_dir, python, os_variants, add_build_str=""):
              combined_spec, config = get_config(recipe_dir)
              print(f"combined_spec: {combined_spec}")
              matrix = {"builds": []}
              variants = []
              for key, value in combined_spec.items():
                  if not isinstance(value, list):
                      continue
                  if len(value) < 2:
                      continue
                  for val in value:
                      var_dict = {key: val}
                      variants.append(var_dict)

              os_map = {
                  "ubuntu-latest": "linux",
                  "windows-latest": "win",
                  "macos-latest": "osx",
              }

              # use itertools to make final build combinations of conda variants, python versions and os's
              if len(variants) == 0:
                  var_dict = {"empty": "empty"}
                  variants.append(var_dict)
          
              itertools_product = itertools.product(python.split(","), os_variants.split(","), variants)
              for python_version, platform, var_dict in itertools_product:
                  build_args = f"--python {python_version}"
                  os_short = os_map[platform]
                  key, val = list(var_dict.items())[0]
                  if key != "empty":
                      build_args += f' --variants="{var_dict}"'
                      header_name = f"{os_short}-{python_version}-{key}={val}"
                  else:
                      header_name = f"{os_short}-{python_version}"
          
                  if add_build_str != "":
                      build_args += add_build_str
          
                  run_object = {
                      "os": platform,
                      "os_short": os_short,
                      "python": python_version,
                      "key": key,
                      "value": val,
                      "header_name": header_name,
                      "build_args": convert_to_byte_str(build_args),
                  }
                  matrix["builds"].append(run_object)
              return matrix
          
          
          toml_data = json.loads(deserialize_str(b"${{ inputs.config_toml_data }}"))
          conda_config = toml_data["tool"]["python"]['conda']
          conda_owner = conda_config.get('owner', 'unset')
          set_output('conda_owner', conda_owner)
          conda_label = conda_config.get('label', 'main')
          set_output('conda_label', conda_label)
          
          extra_conda_channels = conda_config.get('extra_conda_dep_channels', [])
          
          extra_build_str = ""
          for channel in extra_conda_channels:
              extra_build_str += f" -c {channel}"
          
          if "${{ inputs.push_conda }}" == "true":
              extra_build_str += " --no-copy-test-source-files --no-test --no-build-id"
          
          recipe_dir = "${{ needs.extract_conda_meta.outputs.recipe_dir }}"
          add_build_args = "${{ inputs.add_build_args }}"
          platforms = toml_data["tool"]["python"]['conda'].get('platforms', '${{ inputs.platforms }}')
          python_versions = toml_data["tool"]["python"]['conda'].get('python_versions', '${{ inputs.python_versions }}')

          final_matrix = variants_matrix_gen(recipe_dir, python_versions, platforms, extra_build_str)
          set_output('final_matrix', json.dumps(final_matrix))
          print(final_matrix)
          EOF
  
  

  conda_build:
    name: Build "${{ matrix.builds.header_name }}"
    needs: [ create_variant_matrix, extract_conda_meta ]
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.create_variant_matrix.outputs.final_matrix) }}
    runs-on: ${{ matrix.builds.os }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}
      - name: set ENV vars
        run: |
          pwd
          if [[ "$RUNNER_OS" == "Windows" ]]; then
            echo "ARTIFACTS_DIR=D:/a/artifacts" >> $GITHUB_ENV
          elif [[ "$RUNNER_OS" == "macOS" ]]; then
            echo "ARTIFACTS_DIR=/Users/runner/work/artifacts" >> $GITHUB_ENV
          elif [[ "$RUNNER_OS" == "Linux" ]]; then
            echo "using default paths"
          fi      

      - uses: mamba-org/setup-micromamba@v1 # https://github.com/mamba-org/setup-micromamba
        with:
          environment-name: build-env
          cache-environment: true
          condarc: |
            remote_max_retries: 5
            remote_backoff_factor: 5
            channel_priority: strict
            conda-build:
              output_folder: ${{ env.ARTIFACTS_DIR }}
              pkg_format: 2
              zstd_compression_level: 19
            channels:
              - conda-forge
          create-args: >-
            python=3.11
            boa=0.16.0
            toml=0.10.2

      - name: Override version
        if: ${{ inputs.version_override != '' }}
        env:
          VERSION_OVERRIDE: ${{ inputs.version_override }}
        run: |
          python - <<EOF
          import os
          import pathlib
          import toml
          import json
          import base64

          def set_output(name, value):
              with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                  print(f'{name}={value}', file=fh)
          
          def deserialize_str(s):
            return base64.b64decode(s).decode('utf-8')
          
          pyproject_toml_file = list(pathlib.Path('').rglob('pyproject.toml'))[0]
          config_toml_data = json.loads(deserialize_str(b"${{ inputs.config_toml_data }}"))
          
          pre_release_tag = config_toml_data['tool']['python'].get('pre_release_tag', 'dev')

          with open(pyproject_toml_file) as fh:
              pyproject_toml = toml.load(fh)

          version_override = os.getenv('VERSION_OVERRIDE')
          if 'next' in version_override:
              print(f"version_override: {version_override} (before)")
              # replace next. with next to comply with PEP440
              version_override = version_override.replace('-next.', pre_release_tag)
              print(f"pre_release_tag: {pre_release_tag}")
              print(f"version_override: {version_override}")

          pyproject_toml['project']['version'] = version_override

          with open(pyproject_toml_file, 'w') as fh:
              toml.dump(pyproject_toml, fh)
          EOF

      - name: Create variant str
        run: |
          python - <<EOF
          
          import os
          import base64


          def deserialize_str(s):
            return base64.b64decode(s).decode('utf-8')

          build_args = deserialize_str(b"${{ matrix.builds.build_args }}")

          with open(os.environ['GITHUB_ENV'], 'a') as fh:
            print(f"BUILD_ARGS={build_args}", file=fh)
          EOF

      - name: Build conda package
        run: |
          conda mambabuild . ${{ env.BUILD_ARGS }}
        working-directory: ${{ needs.extract_conda_meta.outputs.recipe_dir }}
      - uses: actions/upload-artifact@v4
        with:
          name: conda-${{ format('{0}{1}', github.run_id, github.run_attempts) }}-${{ matrix.builds.os }}-${{ matrix.builds.python }}-${{matrix.builds.key}}-${{matrix.builds.value}}
          retention-days: ${{ needs.extract_conda_meta.outputs.artifacts_retention_days }}
          path: |
            ${{ env.ARTIFACTS_DIR }}

  # Note that the receiving workflow (ie yaml file containing the dispatch triggered job) needs to located in the
  # users directory. Ie. you need to copy the example
  trigger_self_hosted:
    name: Trigger self-hosted runner
    needs: [ conda_build, extract_conda_meta ]
    if: ${{ needs.extract_conda_meta.outputs.publish_runner != 'ubuntu-latest' }}
    runs-on: ubuntu-latest
    steps:
      - name: Trigger self-hosted runner
        if: ${{ inputs.push_conda == 'true' }}
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.repos.createDispatchEvent({
              owner: context.repo.owner,
              repo: context.repo.repo,
              event_type: '${{ needs.extract_conda_meta.outputs.dispatch_release_workflow }}',
              client_payload: {
                artifact_pattern: 'conda-${{ format('{0}{1}', github.run_id, github.run_attempts) }}-*',
                runner_label: 'self-hosted',
                run_id: '${{ github.run_id }}',
                use_quetz_server: '${{ inputs.use_quetz_server }}',
                use_anaconda_server: '${{ inputs.use_anaconda_server }}',
                quetz_channel: '${{ needs.extract_conda_meta.outputs.quetz_channel }}', 
              }
            });
          github-token: ${{ secrets.GITHUB_TOKEN }}

  release_conda:
    name: Release
    if: ${{ needs.extract_conda_meta.outputs.publish_runner == 'ubuntu-latest' }}
    needs: [ conda_build, extract_conda_meta ]
    defaults:
      run:
        shell: bash -l {0}
    runs-on: ubuntu-latest
    steps:
      - uses: mamba-org/setup-micromamba@v1 # https://github.com/mamba-org/setup-micromamba
        with:
          environment-name: publish-env
          cache-environment: true
          create-args: >-
            python=3.11
            toml=0.10.2
            anaconda-client=1.12.1
            quetz-client=0.5.0

      - uses: actions/download-artifact@v4
        with:
          pattern: conda-${{ format('{0}{1}', github.run_id, github.run_attempts) }}-*
          path: my-artifacts
      - name: List artifacts
        shell: python
        run: |
          import pathlib

          for path in pathlib.Path("my-artifacts").rglob("*.conda"):
              print(path)
          
          for path in pathlib.Path("my-artifacts").rglob("*.tar.bz2"):
              print(path)

      - name: Upload packages to Quetz Server
        if: ${{ inputs.use_quetz_server == 'true' && inputs.push_conda == 'true' }}
        env:
          QUETZ_URL: ${{ secrets.QUETZ_URL }}
          QUETZ_API_KEY: ${{ secrets.QUETZ_API_KEY }}
          ARTIFACTS_DIR: my-artifacts
        run: |
          python - <<EOF
          
          import pathlib
          import os
          import requests
          from quetz_client import QuetzClient
          
          quetz_channel = "${{ needs.extract_conda_meta.outputs.quetz_channel }}"
          
          client = QuetzClient.from_token(os.getenv('QUETZ_URL'), os.getenv('QUETZ_API_KEY'))
          
          for conda_file in pathlib.Path(os.getenv('ARTIFACTS_DIR')).rglob('*.conda'):
            print(f"Uploading {conda_file} to channel {quetz_channel}")
            try:
              client.post_file_to_channel(quetz_channel, conda_file, False)
            except requests.exceptions.HTTPError as e:
              print(e)
              # if 409 error, then package already exists
              if e.response.status_code == 409:
                print(f"Likely due to package {conda_file} already exists in channel ${{ matrix.channel }}")
              else:
                raise e
          EOF

      - name: upload for Anaconda
        if: ${{ inputs.use_anaconda_server == 'true' && inputs.push_conda == 'true' }}
        env:
          ANACONDA_TOKEN: ${{ secrets.CONDA_API_TOKEN }}
          ARTIFACTS_DIR: my-artifacts
        run: |
          python - <<EOF
          
          import os
          import pathlib
          import argparse
          from binstar_client.commands.upload import Uploader
          
          artifacts_dir = pathlib.Path(os.getenv('ARTIFACTS_DIR')).resolve().absolute()
          user = '${{ needs.create_variant_matrix.outputs.conda_owner }}'
          label = '${{ needs.create_variant_matrix.outputs.conda_label }}'
          
          arguments = argparse.Namespace(
              token=os.getenv("ANACONDA_TOKEN"),
              user=user,
              label=label,
              labels=[label],
              site=None,
              package_type=None,
              package=None,
              version=None,
              build_id=None,
              summary=None,
              description=None,
              auto_register=True,
              private=False,
              mode="force",
              keep_basename=False,
              force_metadata_update=True,
          )
          uploader: Uploader = Uploader(arguments=arguments)
          uploader.api.check_server()
          _ = uploader.username
          
          try:
              filename: str
              for filename in artifacts_dir.rglob("*.tar.bz2"):
                  uploader.upload(str(filename))
              for filename in artifacts_dir.rglob("*.conda"):
                  uploader.upload(str(filename))
          finally:
              uploader.print_uploads()
              uploader.cleanup()
          
          EOF
